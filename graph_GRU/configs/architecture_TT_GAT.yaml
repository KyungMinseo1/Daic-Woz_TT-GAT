training:
  lr: 0.00005
  weight-decay: 0.001
  bs: 4
  scheduler: 'reducelr'
  warmup_epoch: 5
  focal_alpha: 0.75
  focal_gamma: 3
  gamma: 0.5
  step-size: 50
  embed_model: 'sentence-transformers/all-MiniLM-L6-v2'
  time_interval: 10

model:
  h_dim: 256
  head: 8
  num_layers: 3
  gru_num_layers: 2
  t_dropout: 0.3
  g_dropout: 0.3
  v_dropout: 0.3
  a_dropout: 0.3
  use_attention: True
  use_summary_node: False
  use_text_proj: True