{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd21172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pegoo\\anaconda3\\envs\\graph_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91919e8d",
   "metadata": {},
   "source": [
    "## CREATE VISUAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eccfb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:06<00:00, 28.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(os.listdir(config.RAW_DATA_DIR)):\n",
    "  target_f_name = f[:3]\n",
    "  if not os.path.isdir(os.path.join(config.RAW_DATA_DIR, f)):\n",
    "    continue\n",
    "  elif f\"{target_f_name}_vision_summary.csv\" in os.listdir(os.path.join(config.DATA_DIR, 'Vision Summary')):\n",
    "    continue\n",
    "  else:\n",
    "    data_path = os.path.join(config.RAW_DATA_DIR, f)\n",
    "    clnf_au = os.path.join(data_path, f'{target_f_name}_CLNF_AUs.txt')\n",
    "    clnf_ft = os.path.join(data_path, f'{target_f_name}_CLNF_features.txt')\n",
    "    clnf_ft_3d = os.path.join(data_path, f'{target_f_name}_CLNF_features3D.txt')\n",
    "    clnf_gz = os.path.join(data_path, f'{target_f_name}_CLNF_gaze.txt')\n",
    "    clnf_ps = os.path.join(data_path, f'{target_f_name}_CLNF_pose.txt')\n",
    "    ft_df = pd.read_csv(clnf_ft, sep=', ', engine='python', encoding='utf-8')\n",
    "    ft_3d_df = pd.read_csv(clnf_ft_3d, sep=', ', engine='python', encoding='utf-8')\n",
    "    au_df = pd.read_csv(clnf_au, sep=', ', engine='python', encoding='utf-8')\n",
    "    gz_df = pd.read_csv(clnf_gz, sep=',', engine='python', encoding='utf-8')\n",
    "    ps_df = pd.read_csv(clnf_ps, sep=', ', engine='python', encoding='utf-8')\n",
    "    uni_col = list(set(ft_df.columns) & set(au_df.columns))\n",
    "    uni = ft_df[uni_col]\n",
    "    ft_df.columns = 'ft' + ft_df.columns\n",
    "    ft_3d_df.columns = 'ft_3d' + ft_3d_df.columns\n",
    "    au_df.columns = 'au' + au_df.columns\n",
    "    gz_df.columns = 'gz' + gz_df.columns\n",
    "    ps_df.columns = 'ps' + ps_df.columns\n",
    "    ft_x = ft_df.filter(like='x')\n",
    "    ft_y = ft_df.filter(like='y')\n",
    "    ft_3d_x = ft_3d_df.filter(like='X')\n",
    "    ft_3d_y = ft_3d_df.filter(like='Y')\n",
    "    ft_3d_z = ft_3d_df.filter(like='Z')\n",
    "    au_r = au_df.filter(like='_r')\n",
    "    au_c = au_df.filter(like='_c')\n",
    "    condition_include = gz_df.columns.str.contains('_')\n",
    "    condition_exclude = ~gz_df.columns.str.contains('h')\n",
    "    final_mask = condition_include & condition_exclude\n",
    "    gz_raw = gz_df.loc[:, final_mask]\n",
    "    gz_h = gz_df.filter(like='h')\n",
    "    ps_t = ps_df.filter(like='T')\n",
    "    ps_r = ps_df.filter(like='R')\n",
    "    merged_df = pd.concat([uni, ft_x, ft_y, ft_3d_x, ft_3d_y, ft_3d_z, au_r, au_c, gz_raw, gz_h, ps_t, ps_r], axis=1)\n",
    "    merged_df.to_csv(os.path.join(config.DATA_DIR, 'Vision Summary', f'{target_f_name}_vision_summary.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60dab96",
   "metadata": {},
   "source": [
    "## PROCESS TEXT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff3cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 363부터 달라짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71edcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:00<00:00, 7228.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(os.listdir(config.RAW_DATA_DIR)):\n",
    "  target_f_name = f[:3]\n",
    "  if not os.path.isdir(os.path.join(config.RAW_DATA_DIR, f)):\n",
    "    continue\n",
    "  elif f\"{target_f_name}_transcript.csv\" in os.listdir(os.path.join(config.DATA_DIR, 'Transcription')):\n",
    "    continue\n",
    "  else:\n",
    "    text_df = pd.read_csv(os.path.join(config.RAW_DATA_DIR, f'{target_f_name}_P', f'{target_f_name}_TRANSCRIPT.csv'), sep='\\t')\n",
    "    text_df.to_csv(os.path.join(config.DATA_DIR, 'Transcription', f'{target_f_name}_transcript.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9c01a",
   "metadata": {},
   "source": [
    "## PROCESS AUDIO FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d71866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(x):\n",
    "  return x.mean(), x.min(), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6b29a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:00<00:00, 725.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# check column number 10\n",
    "col_10_lst = []\n",
    "col_36_lst = []\n",
    "col_37_lst = []\n",
    "col_38_lst = []\n",
    "col_39_lst = []\n",
    "for f in tqdm(os.listdir(config.RAW_DATA_DIR)):\n",
    "  if not os.path.isdir(os.path.join(config.RAW_DATA_DIR, f)):\n",
    "    continue\n",
    "  elif f\"{target_f_name}_audio_summary.csv\" in os.listdir(os.path.join(config.DATA_DIR, 'Audio Summary')):\n",
    "    continue\n",
    "  else:\n",
    "    target_f_name=f[:3]\n",
    "    covarep_df = pd.read_csv(os.path.join(config.RAW_DATA_DIR, f'{target_f_name}_P', f'{target_f_name}_COVAREP.csv'), header=None)\n",
    "    stats_10 = calculate_stats(covarep_df.iloc[:, 10])\n",
    "    stats_36 = calculate_stats(covarep_df.iloc[:, 36])\n",
    "    stats_37 = calculate_stats(covarep_df.iloc[:, 37])\n",
    "    stats_38 = calculate_stats(covarep_df.iloc[:, 38])\n",
    "    stats_39 = calculate_stats(covarep_df.iloc[:, 39])\n",
    "    col_10_lst.append(stats_10)\n",
    "    col_36_lst.append(stats_36)\n",
    "    col_37_lst.append(stats_37)\n",
    "    col_38_lst.append(stats_38)\n",
    "    col_39_lst.append(stats_39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac8656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10번 열 통계량(mean, min, max) [0. 0. 0.]\n",
      "36번 열 통계량(mean, min, max) [0. 0. 0.]\n",
      "37번 열 통계량(mean, min, max) [0. 0. 0.]\n",
      "38번 열 통계량(mean, min, max) [0. 0. 0.]\n",
      "39번 열 통계량(mean, min, max) [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "col_10_np = np.array(col_10_lst)\n",
    "col_36_np = np.array(col_36_lst)\n",
    "col_37_np = np.array(col_37_lst)\n",
    "col_38_np = np.array(col_38_lst)\n",
    "col_39_np = np.array(col_39_lst)\n",
    "\n",
    "print('10번 열 통계량(mean, min, max)', np.mean(col_10_np, axis=0))\n",
    "print('36번 열 통계량(mean, min, max)',np.mean(col_36_np, axis=0))\n",
    "print('37번 열 통계량(mean, min, max)',np.mean(col_37_np, axis=0))\n",
    "print('38번 열 통계량(mean, min, max)',np.mean(col_38_np, axis=0))\n",
    "print('39번 열 통계량(mean, min, max)',np.mean(col_39_np, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45044bdd",
   "metadata": {},
   "source": [
    "covarep 파일의 (0번부터 시작) 10번, 36번, 37번, 38번, 39번은 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb2c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.5 0.0 0.089742 0.32257 2.9205 0.12642 0.10171 -0.42546 1.2936 0.471 0.0 -8.5767 2.0857 -0.22174 0.47126 0.03297 -0.068466 -0.065727 0.014886 0.02652 0.15883 -0.04209 0.036558 -0.10241 0.19617 -0.28809 0.025842 0.1255 -0.12538 -0.049855 0.14323 -0.010365 0.087629 -0.067861 0.10681 -0.0676 0.0 0.0 0.0 0.0 0.0 0.0 0.0066048 -0.079718 -0.36235 -2.5475 2.5188 1.8819 1.9136 1.7211 2.0634 2.1656 2.0323 2.2115 2.0762 1.9933 2.0794 2.3189 2.0805 2.6563 2.936 -0.041149 -0.74974 -0.68285 -0.65799 -0.66151 -0.68335 -0.6321 -0.57434 -0.52392 -0.49954 -0.42295 -0.3791 -0.36672 \n",
      "92.5 0.0 0.089742 0.32257 2.9205 0.12642 0.10171 -0.42546 1.2936 0.471 -8.5767 2.0857 -0.22174 0.47126 0.03297 -0.068466 -0.065727 0.014886 0.02652 0.15883 -0.04209 0.036558 -0.10241 0.19617 -0.28809 0.025842 0.1255 -0.12538 -0.049855 0.14323 -0.010365 0.087629 -0.067861 0.10681 -0.0676 0.0 0.0 0.0066048 -0.079718 -0.36235 -2.5475 2.5188 1.8819 1.9136 1.7211 2.0634 2.1656 2.0323 2.2115 2.0762 1.9933 2.0794 2.3189 2.0805 2.6563 2.936 -0.041149 -0.74974 -0.68285 -0.65799 -0.66151 -0.68335 -0.6321 -0.57434 -0.52392 -0.49954 -0.42295 -0.3791 -0.36672 "
     ]
    }
   ],
   "source": [
    "target_f_name='301'\n",
    "temp_col = [74, 75, 76, 77, 78]\n",
    "sample_df = pd.read_csv(os.path.join(config.RAW_DATA_DIR, f'{target_f_name}_P', f'{target_f_name}_COVAREP.csv'), header=None)\n",
    "sample_f_df = pd.read_csv(os.path.join(config.RAW_DATA_DIR, f'{target_f_name}_P', f'{target_f_name}_FORMANT.csv'), header=None)\n",
    "sample_f_df.columns = temp_col\n",
    "delete_target_col = [sample_df.columns[10], sample_df.columns[36], sample_df.columns[37], sample_df.columns[38], sample_df.columns[39]]\n",
    "new_df = sample_df.drop(delete_target_col, axis=1)\n",
    "s_30000 = sample_df.iloc[30000]\n",
    "n_30000 = new_df.iloc[30000]\n",
    "for s in s_30000:\n",
    "  print(s, end = ' ')\n",
    "print()\n",
    "for n in n_30000:\n",
    "  print(n, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51eef89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82389, 82390)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_df), len(sample_f_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b3c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:02<00:00, 72.83it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_col = [74, 75, 76, 77, 78]\n",
    "for f in tqdm(os.listdir(config.RAW_DATA_DIR)):\n",
    "  target_f_name=f[:3]\n",
    "  if not os.path.isdir(os.path.join(config.RAW_DATA_DIR, f)):\n",
    "    continue\n",
    "  elif f\"{target_f_name}_audio_summary.csv\" in os.listdir(os.path.join(config.DATA_DIR, 'Audio Summary')):\n",
    "    continue\n",
    "  else:\n",
    "    covarep_df = pd.read_csv(os.path.join(config.RAW_DATA_DIR, f'{target_f_name}_P', f'{target_f_name}_COVAREP.csv'), header=None)\n",
    "    formant_df = pd.read_csv(os.path.join(config.RAW_DATA_DIR, f'{target_f_name}_P', f'{target_f_name}_FORMANT.csv'), header=None)\n",
    "    formant_df.columns = temp_col\n",
    "    delete_target_col = [covarep_df.columns[10], covarep_df.columns[36], covarep_df.columns[37], covarep_df.columns[38], covarep_df.columns[39]]\n",
    "    covarep_dropped = covarep_df.drop(delete_target_col, axis=1)\n",
    "    audio_summary = pd.concat([covarep_dropped, formant_df], axis=1).dropna()\n",
    "    audio_summary.to_csv(os.path.join(config.DATA_DIR, 'Audio Summary', f'{target_f_name}_audio_summary.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
