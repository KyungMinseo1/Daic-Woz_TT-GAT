{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b270d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from multiprocessing import Manager\n",
    "from multiprocessing.pool import Pool\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import gensim.downloader as api\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dacb1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe TXT 파일을 Word2Vec 형식으로 변환 중입니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Local\\Temp\\ipykernel_18096\\3540372230.py:23: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_txt_file, word2vec_bin_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 완료.\n"
     ]
    }
   ],
   "source": [
    "# 1. 파일 경로 설정 (경로는 사용 환경에 맞게 수정해야 합니다)\n",
    "glove_txt_file = os.path.join(config.MODEL_DIR, 'glove.840B.300d.txt')\n",
    "word2vec_bin_file = os.path.join(config.MODEL_DIR, \"glove.840B.300d.word2vec.bin\")\n",
    "\n",
    "# 2. GloVe TXT 파일을 Word2Vec 형식으로 변환\n",
    "print(\"GloVe TXT 파일을 Word2Vec 형식으로 변환 중입니다...\")\n",
    "# 이 과정은 파일 크기가 크기 때문에 약 10~30분 소요될 수 있습니다.\n",
    "if not os.path.exists(word2vec_bin_file):\n",
    "    glove2word2vec(glove_txt_file, word2vec_bin_file)\n",
    "    print(\"변환 완료.\")\n",
    "else:\n",
    "    print(\"변환된 파일이 이미 존재합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74d2c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환된 바이너리 파일을 메모리에 로드 중입니다...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.45 GiB for an array with shape (2196017, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m변환된 바이너리 파일을 메모리에 로드 중입니다...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 로드도 용량이 크기 때문에 수 분이 소요될 수 있습니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m glove_model = \u001b[43mKeyedVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword2vec_bin_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatin-1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m모델 로드 완료. 총 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(glove_model.index_to_key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개의 단어 벡터가 로드되었습니다.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# --- 모델 사용 예시 ---\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. 단어 임베딩 벡터 얻기\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\82102\\anaconda3\\envs\\multimodal_env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1721\u001b[39m, in \u001b[36mKeyedVectors.load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[39m\n\u001b[32m   1674\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1675\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_word2vec_format\u001b[39m(\n\u001b[32m   1676\u001b[39m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab=\u001b[38;5;28;01mNone\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m'\u001b[39m, unicode_errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1677\u001b[39m         limit=\u001b[38;5;28;01mNone\u001b[39;00m, datatype=REAL, no_header=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1678\u001b[39m     ):\n\u001b[32m   1679\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[32m   1680\u001b[39m \n\u001b[32m   1681\u001b[39m \u001b[33;03m    Warnings\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1719\u001b[39m \n\u001b[32m   1720\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1721\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\82102\\anaconda3\\envs\\multimodal_env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2064\u001b[39m, in \u001b[36m_load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[39m\n\u001b[32m   2062\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit:\n\u001b[32m   2063\u001b[39m     vocab_size = \u001b[38;5;28mmin\u001b[39m(vocab_size, limit)\n\u001b[32m-> \u001b[39m\u001b[32m2064\u001b[39m kv = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[32m   2067\u001b[39m     _word2vec_read_binary(\n\u001b[32m   2068\u001b[39m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[32m   2069\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\82102\\anaconda3\\envs\\multimodal_env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:245\u001b[39m, in \u001b[36mKeyedVectors.__init__\u001b[39m\u001b[34m(self, vector_size, count, dtype, mapfile_path)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28mself\u001b[39m.next_index = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# pointer to where next new entry will land\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;28mself\u001b[39m.key_to_index = {}\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[38;5;28mself\u001b[39m.vectors = \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# formerly known as syn0\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;28mself\u001b[39m.norms = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# \"expandos\" are extra attributes stored for each key: {attribute_name} => numpy array of values of\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# this attribute, with one array value for each vector key.\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# The same information used to be stored in a structure called Vocab in Gensim <4.0.0, but\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# with different indexing: {vector key} => Vocab object containing all attributes for the given vector key.\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# Don't modify expandos directly; call set_vecattr()/get_vecattr() instead.\u001b[39;00m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 2.45 GiB for an array with shape (2196017, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "word2vec_bin_file = os.path.join(config.MODEL_DIR, \"glove.840B.300d.word2vec.bin\")\n",
    "# 1. Word2Vec 형식 바이너리 파일 로드\n",
    "print(\"변환된 바이너리 파일을 메모리에 로드 중입니다...\")\n",
    "# 로드도 용량이 크기 때문에 수 분이 소요될 수 있습니다.\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_bin_file, binary=True, encoding='latin-1')\n",
    "print(f\"모델 로드 완료. 총 {len(glove_model.index_to_key)}개의 단어 벡터가 로드되었습니다.\")\n",
    "\n",
    "# --- 모델 사용 예시 ---\n",
    "\n",
    "# 2. 단어 임베딩 벡터 얻기\n",
    "word_vector = glove_model['interview']\n",
    "print(f\"\\n'interview' 단어의 임베딩 벡터 (처음 5개 차원): {word_vector[:5]}\")\n",
    "print(f\"임베딩 벡터 차원: {len(word_vector)}\")\n",
    "\n",
    "# 3. 단어 유사성 계산\n",
    "similarity = glove_model.similarity('question', 'query')\n",
    "print(f\"\\n'question'과 'query'의 유사도: {similarity:.4f}\")\n",
    "\n",
    "# 4. 가장 유사한 단어 찾기\n",
    "similar_words = glove_model.most_similar('job', topn=5)\n",
    "print(f\"\\n'job'과 가장 유사한 단어 5가지:\\n{similar_words}\")\n",
    "\n",
    "# 5. 단어 유추 (Analogy)\n",
    "# 예를 들어, 'France' - 'Paris' + 'Tokyo' = 'Japan'\n",
    "analogy_result = glove_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(f\"\\nKing - Man + Woman = {analogy_result[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c8ae0",
   "metadata": {},
   "source": [
    "## Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a9c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t_df = pd.read_csv(os.path.join(config.DATA_DIR, 'Transcription', os.listdir(os.path.join(config.DATA_DIR, 'Transcription'))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0aa329",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_not_ellie = sample_t_df['speaker'] != 'Ellie'\n",
    "new_group_start = (is_not_ellie) & (~is_not_ellie.shift(1, fill_value=False))\n",
    "group_id = new_group_start.cumsum()\n",
    "sample_t_df['count'] = group_id.where(is_not_ellie, None)\n",
    "sample_t_df.loc[~is_not_ellie, 'count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f43d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df = sample_t_df[~pd.isna(sample_t_df['count'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81b44a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62.328</td>\n",
       "      <td>63.178</td>\n",
       "      <td>Participant</td>\n",
       "      <td>good</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68.978</td>\n",
       "      <td>70.288</td>\n",
       "      <td>Participant</td>\n",
       "      <td>atlanta georgia</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75.028</td>\n",
       "      <td>78.128</td>\n",
       "      <td>Participant</td>\n",
       "      <td>um my parents are from here um</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>83.808</td>\n",
       "      <td>84.588</td>\n",
       "      <td>Participant</td>\n",
       "      <td>i love it</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>88.458</td>\n",
       "      <td>89.968</td>\n",
       "      <td>Participant</td>\n",
       "      <td>i like the weather</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90.278</td>\n",
       "      <td>93.568</td>\n",
       "      <td>Participant</td>\n",
       "      <td>i like the opportunities</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>94.738</td>\n",
       "      <td>95.298</td>\n",
       "      <td>Participant</td>\n",
       "      <td>um</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>96.588</td>\n",
       "      <td>97.278</td>\n",
       "      <td>Participant</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>102.428</td>\n",
       "      <td>103.268</td>\n",
       "      <td>Participant</td>\n",
       "      <td>um</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104.278</td>\n",
       "      <td>105.558</td>\n",
       "      <td>Participant</td>\n",
       "      <td>it took a minute</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_time  stop_time      speaker                           value  count\n",
       "6       62.328     63.178  Participant                            good    1.0\n",
       "9       68.978     70.288  Participant                 atlanta georgia    2.0\n",
       "12      75.028     78.128  Participant  um my parents are from here um    3.0\n",
       "14      83.808     84.588  Participant                       i love it    4.0\n",
       "16      88.458     89.968  Participant              i like the weather    5.0\n",
       "17      90.278     93.568  Participant        i like the opportunities    5.0\n",
       "18      94.738     95.298  Participant                              um    5.0\n",
       "19      96.588     97.278  Participant                             yes    5.0\n",
       "21     102.428    103.268  Participant                              um    6.0\n",
       "22     104.278    105.558  Participant                it took a minute    6.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3168797f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like the weather i like the opportunities um yes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(participant_df.loc[participant_df['count']==5.0].value.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287460d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = participant_df.dropna(subset=['count']).groupby('count').agg(\n",
    "    start_time=('start_time', 'min'), # 그룹의 가장 이른 시작 시간\n",
    "    stop_time=('stop_time', 'max')   # 그룹의 가장 늦은 종료 시간\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33022773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>62.328</td>\n",
       "      <td>63.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>68.978</td>\n",
       "      <td>70.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>75.028</td>\n",
       "      <td>78.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>83.808</td>\n",
       "      <td>84.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>88.458</td>\n",
       "      <td>97.278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  start_time  stop_time\n",
       "0    1.0      62.328     63.178\n",
       "1    2.0      68.978     70.288\n",
       "2    3.0      75.028     78.128\n",
       "3    4.0      83.808     84.588\n",
       "4    5.0      88.458     97.278"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a59f50d",
   "metadata": {},
   "source": [
    "## Visual Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07126b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_v_df = pd.read_csv(os.path.join(config.DATA_DIR, 'Vision Summary', os.listdir(os.path.join(config.DATA_DIR, 'Vision Summary'))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd3e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = sample_v_df.timestamp\n",
    "ft_x = sample_v_df.filter(like='ftx')\n",
    "ft_y = sample_v_df.filter(like='fty')\n",
    "ft_3d_x = sample_v_df.filter(like='ft_3dX')\n",
    "ft_3d_y = sample_v_df.filter(like='ft_3dY')\n",
    "ft_3d_z = sample_v_df.filter(like='ft_3dZ')\n",
    "au_r = sample_v_df.filter(like='au').filter(like='_r')\n",
    "au_c = sample_v_df.filter(like='au').filter(like='_c')\n",
    "gz_df = sample_v_df.filter(like='gz')\n",
    "condition_include = gz_df.columns.str.contains('_')\n",
    "condition_exclude = ~gz_df.columns.str.contains('h')\n",
    "final_mask = condition_include & condition_exclude\n",
    "gz_raw = gz_df.loc[:, final_mask]\n",
    "gz_h = gz_df.filter(like='h')\n",
    "ps_t = sample_v_df.filter(like='ps').filter(like='T')\n",
    "ps_r = sample_v_df.filter(like='ps').filter(like='R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b712cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision = pd.concat([timestamp, au_r, gz_h, ps_t, ps_r], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c28a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "upgrade_vision = pd.concat([timestamp, ft_x, ft_y, ft_3d_x, ft_3d_y, ft_3d_z, au_r, gz_h, ps_t, ps_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dfd048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ftx0</th>\n",
       "      <th>ftx1</th>\n",
       "      <th>ftx2</th>\n",
       "      <th>ftx3</th>\n",
       "      <th>ftx4</th>\n",
       "      <th>ftx5</th>\n",
       "      <th>ftx6</th>\n",
       "      <th>ftx7</th>\n",
       "      <th>ftx8</th>\n",
       "      <th>...</th>\n",
       "      <th>gz z_h0</th>\n",
       "      <th>gz x_h1</th>\n",
       "      <th>gz y_h1</th>\n",
       "      <th>gz z_h1</th>\n",
       "      <th>psTx</th>\n",
       "      <th>psTy</th>\n",
       "      <th>psTz</th>\n",
       "      <th>psRx</th>\n",
       "      <th>psRy</th>\n",
       "      <th>psRz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19453</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441858</td>\n",
       "      <td>-0.093022</td>\n",
       "      <td>-0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19454</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430105</td>\n",
       "      <td>-0.082108</td>\n",
       "      <td>-0.212567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19455</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>-0.079041</td>\n",
       "      <td>-0.192886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19456</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473191</td>\n",
       "      <td>-0.077877</td>\n",
       "      <td>-0.174793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469507</td>\n",
       "      <td>-0.079453</td>\n",
       "      <td>-0.161602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194580 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  ftx0  ftx1  ftx2  ftx3  ftx4  ftx5  ftx6  ftx7  ftx8  ...  \\\n",
       "0       0.000000   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1       0.033333   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2       0.066667   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3       0.100000   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4       0.133333   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "19453        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "19454        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "19455        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "19456        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "19457        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "       gz z_h0  gz x_h1  gz y_h1  gz z_h1  psTx  psTy  psTz      psRx  \\\n",
       "0          NaN      NaN      NaN      NaN   NaN   NaN   NaN       NaN   \n",
       "1          NaN      NaN      NaN      NaN   NaN   NaN   NaN       NaN   \n",
       "2          NaN      NaN      NaN      NaN   NaN   NaN   NaN       NaN   \n",
       "3          NaN      NaN      NaN      NaN   NaN   NaN   NaN       NaN   \n",
       "4          NaN      NaN      NaN      NaN   NaN   NaN   NaN       NaN   \n",
       "...        ...      ...      ...      ...   ...   ...   ...       ...   \n",
       "19453      NaN      NaN      NaN      NaN   NaN   NaN   NaN  0.441858   \n",
       "19454      NaN      NaN      NaN      NaN   NaN   NaN   NaN  0.430105   \n",
       "19455      NaN      NaN      NaN      NaN   NaN   NaN   NaN  0.458600   \n",
       "19456      NaN      NaN      NaN      NaN   NaN   NaN   NaN  0.473191   \n",
       "19457      NaN      NaN      NaN      NaN   NaN   NaN   NaN  0.469507   \n",
       "\n",
       "           psRy      psRz  \n",
       "0           NaN       NaN  \n",
       "1           NaN       NaN  \n",
       "2           NaN       NaN  \n",
       "3           NaN       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "19453 -0.093022 -0.228571  \n",
       "19454 -0.082108 -0.212567  \n",
       "19455 -0.079041 -0.192886  \n",
       "19456 -0.077877 -0.174793  \n",
       "19457 -0.079453 -0.161602  \n",
       "\n",
       "[194580 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upgrade_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c2d440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 -> 648.567\n"
     ]
    }
   ],
   "source": [
    "print(vision.timestamp.min(), '->', vision.timestamp.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c42e3d",
   "metadata": {},
   "source": [
    "## Audio Encoding (Every row = 0.01s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a8d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_a_df = pd.read_csv(os.path.join(config.DATA_DIR, 'Audio Summary', os.listdir(os.path.join(config.DATA_DIR, 'Audio Summary'))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ddbda99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 64849\n"
     ]
    }
   ],
   "source": [
    "print(sample_a_df.index.min(), '->', sample_a_df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d34282",
   "metadata": {},
   "source": [
    "## Using Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8aa624a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr = Manager()\n",
    "dataset = mgr.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b7bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def process_transcription(df):\n",
    "  is_not_ellie = df['speaker'] != 'Ellie'\n",
    "  new_group_start = (is_not_ellie) & (~is_not_ellie.shift(1, fill_value=False))\n",
    "  group_id = new_group_start.cumsum()\n",
    "  df['count'] = group_id.where(is_not_ellie, None)\n",
    "  df.loc[~is_not_ellie, 'count'] = None\n",
    "  participant_df = df[~pd.isna(df['count'])]\n",
    "  group_df = participant_df.dropna(subset=['count']).groupby('count').agg(\n",
    "      start_time=('start_time', 'min'), # 그룹의 가장 이른 시작 시간\n",
    "      stop_time=('stop_time', 'max')   # 그룹의 가장 늦은 종료 시간\n",
    "  ).reset_index()\n",
    "  return participant_df, group_df\n",
    "\n",
    "def process_vision(df):\n",
    "  timestamp = df.timestamp\n",
    "  au_r = df.filter(like='au').filter(like='_r')\n",
    "  gz_df = df.filter(like='gz')\n",
    "  gz_h = gz_df.filter(like='h')\n",
    "  ps_t = df.filter(like='ps').filter(like='T')\n",
    "  ps_r = df.filter(like='ps').filter(like='R')\n",
    "  vision = pd.concat([timestamp, au_r, gz_h, ps_t, ps_r], axis=1)\n",
    "  return vision\n",
    "\n",
    "def read_tva(id, dataset):\n",
    "  try:\n",
    "    TRANSCRIPTION = []\n",
    "    VISION = []\n",
    "    AUDIO = []\n",
    "    t_df = pd.read_csv(os.path.join(config.DATA_DIR, 'Transcription', f'{id}_transcript.csv'))\n",
    "    v_df = pd.read_csv(os.path.join(config.DATA_DIR, 'Vision Summary', f'{id}_vision_summary.csv'))\n",
    "    a_df = pd.read_csv(os.path.join(config.DATA_DIR, 'Audio Summary', f'{id}_audio_summary.csv'))\n",
    "\n",
    "    participant_df, group_df = process_transcription(t_df)\n",
    "    vision = process_vision(v_df)\n",
    "\n",
    "    for _, row in group_df.iterrows():\n",
    "      start = row.start_time\n",
    "      stop = row.stop_time\n",
    "      t_target = participant_df.loc[participant_df['count']==row['count']]\n",
    "      v_target = vision.loc[(start <= vision.timestamp) & (vision.timestamp <= stop)]\n",
    "      v_target = v_target.drop(columns=['timestamp'])\n",
    "      v_target_list = v_target.values.tolist()\n",
    "      a_target = a_df.iloc[int(start*100):int((stop*100)+1)]\n",
    "      a_target_list = a_target.values.tolist()\n",
    "      if len(t_target) > 0:\n",
    "        TRANSCRIPTION.append(t_target)\n",
    "      else:\n",
    "        print(\"ERROR in transcription\")\n",
    "      if len(v_target_list) > 0:\n",
    "        VISION.append(v_target_list)\n",
    "      else:\n",
    "        print(\"ERROR in vision\")\n",
    "      if len(a_target_list) > 0:\n",
    "        AUDIO.append(a_target_list)\n",
    "      else:\n",
    "        print(\"ERROR in vision\")\n",
    "    if len(TRANSCRIPTION) == len(VISION) == len(AUDIO):\n",
    "      dataset.append((TRANSCRIPTION, VISION, AUDIO))\n",
    "    else:\n",
    "      print(\"Length Not Matched\")\n",
    "  except Exception as e:\n",
    "    print(\"오류 발생:\",e)\n",
    "\n",
    "id = ['300']\n",
    "with Pool(processes=10) as p:\n",
    "  with tqdm(total=len(id)) as pbar:\n",
    "    for v in p.imap_unordered(partial(read_tva, dataset=dataset),id):\n",
    "      pbar.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
